{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fcIzCEsksJqMaWdpCdlnvKI4VBVesPL3","timestamp":1702992745035},{"file_id":"1bR9Z-AtScTGlE3B46qMpQKsPRCJw2fYc","timestamp":1602093612059},{"file_id":"1FYN-4bl_tK6DYaXAutJsIlWLbmq56MbQ","timestamp":1602019879270}],"collapsed_sections":["JmDcELnJOBTq","NXCgPeVVOby6"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7c0p0eWP672d"},"source":["# Detectando objetos em vídeos com YOLOv4 e OpenCV"]},{"cell_type":"markdown","metadata":{"id":"qdqDEz3C7Gsw"},"source":["## Etapa 1 - Importando as bibliotecas"]},{"cell_type":"code","metadata":{"id":"G6Sl5Vhf4q0e","executionInfo":{"status":"ok","timestamp":1702992840294,"user_tz":180,"elapsed":322,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"4904cae1-3f5f-498c-a4e8-2d236980329f","colab":{"base_uri":"https://localhost:8080/"}},"source":["import cv2\n","print(cv2.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["4.8.0\n"]}]},{"cell_type":"code","metadata":{"id":"iRBF8b5o0Ae7","executionInfo":{"status":"ok","timestamp":1602094255663,"user_tz":180,"elapsed":11978,"user":{"displayName":"Jones Granatyr","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1vUcILJyejpiALYfXnvgrtnI3znzTkyT9vBtGGw=s64","userId":"10042675233362078631"}},"outputId":"cdccadba-d233-4d09-eb9a-67f9dd34ab05","colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["!pip install opencv-python==4.4.0.40"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting opencv-python==4.4.0.40\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/8a/7a01233c28f4f0b49536498f2ae39aa9f70c6de85fe74dc17f53ec7d0b0e/opencv_python-4.4.0.40-cp36-cp36m-manylinux2014_x86_64.whl (49.4MB)\n","\u001b[K     |████████████████████████████████| 49.4MB 81kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==4.4.0.40) (1.18.5)\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: opencv-python\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","Successfully installed opencv-python-4.4.0.40\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["cv2"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ONee8yfzbFJp","executionInfo":{"status":"ok","timestamp":1702992877604,"user_tz":180,"elapsed":267,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"fe069423-b82f-4b73-9d92-d34f5efec7b0","colab":{"base_uri":"https://localhost:8080/"}},"source":["import cv2\n","import numpy as np\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow\n","import zipfile\n","print(cv2.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["4.8.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"05vKSzso7Kvw"},"source":["## Etapa 2 - Conectando com o Google Drive"]},{"cell_type":"code","metadata":{"id":"LlXvULPEa-bZ","executionInfo":{"status":"ok","timestamp":1702993162161,"user_tz":180,"elapsed":266191,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"e2db3142-1ebd-4dfd-ad58-a26f1ba1ef42","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"PxlRGgZV7d_r"},"source":["## Etapa 3 - Carregando os arquivos do modelo treinado"]},{"cell_type":"code","metadata":{"id":"-TmtEny4sdyH","executionInfo":{"status":"ok","timestamp":1702993473207,"user_tz":180,"elapsed":7578,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["path =  '/content/gdrive/MyDrive/Yolo/YoloV4Files.zip'\n","zip_object = zipfile.ZipFile(file=path, mode=\"r\")\n","zip_object.extractall(\"./\")\n","zip_object.close()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jkGd4ASWbLk5","executionInfo":{"status":"ok","timestamp":1702993596755,"user_tz":180,"elapsed":261,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["labels_path = os.path.sep.join(['/content/cfg', \"coco.names\"])#Read the labels file\n","LABELS = open(labels_path).read().strip().split(\"\\n\")#Loads the label"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAP1oeyfGXdi","executionInfo":{"status":"ok","timestamp":1702993598024,"user_tz":180,"elapsed":2,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["weights_path = os.path.sep.join(['/content/', \"yolov4.weights\"])#Read the config file\n","config_path = os.path.sep.join(['/content/cfg', \"yolov4.cfg\"])#Loads the config"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"voiXcNqEGZkd","executionInfo":{"status":"ok","timestamp":1702993599612,"user_tz":180,"elapsed":1321,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["net = cv2.dnn.readNet(config_path, weights_path)#Loads the neural network"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O3zdFwT881pS"},"source":["## Etapa 4 - Definindo mais configurações para a detecção"]},{"cell_type":"code","metadata":{"id":"Dul5BbIkKaqj","executionInfo":{"status":"ok","timestamp":1702993601118,"user_tz":180,"elapsed":304,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["np.random.seed(42)#Define the seed of the random value\n","COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")#Create a random array of colors"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"RRrXAEWHs27Y","executionInfo":{"status":"ok","timestamp":1702993695297,"user_tz":180,"elapsed":369,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"09cff1c1-69cc-4682-8c68-a11fc6a475a9","colab":{"base_uri":"https://localhost:8080/"}},"source":["ln = net.getLayerNames()#Get the layers names\n","print(\"Todas as camadas (layers):\")\n","print(ln)\n","print(\"Total: \"+ str(len(ln)))\n","print(\"Camadas de saída: \")\n","print(net.getUnconnectedOutLayers())#Get the output layers index\n","ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n","print(ln)#Show the output layers names"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Todas as camadas (layers):\n","('conv_0', 'bn_0', 'mish_1', 'conv_1', 'bn_1', 'mish_2', 'conv_2', 'bn_2', 'mish_3', 'identity_3', 'conv_4', 'bn_4', 'mish_5', 'conv_5', 'bn_5', 'mish_6', 'conv_6', 'bn_6', 'mish_7', 'shortcut_7', 'conv_8', 'bn_8', 'mish_9', 'concat_9', 'conv_10', 'bn_10', 'mish_11', 'conv_11', 'bn_11', 'mish_12', 'conv_12', 'bn_12', 'mish_13', 'identity_13', 'conv_14', 'bn_14', 'mish_15', 'conv_15', 'bn_15', 'mish_16', 'conv_16', 'bn_16', 'mish_17', 'shortcut_17', 'conv_18', 'bn_18', 'mish_19', 'conv_19', 'bn_19', 'mish_20', 'shortcut_20', 'conv_21', 'bn_21', 'mish_22', 'concat_22', 'conv_23', 'bn_23', 'mish_24', 'conv_24', 'bn_24', 'mish_25', 'conv_25', 'bn_25', 'mish_26', 'identity_26', 'conv_27', 'bn_27', 'mish_28', 'conv_28', 'bn_28', 'mish_29', 'conv_29', 'bn_29', 'mish_30', 'shortcut_30', 'conv_31', 'bn_31', 'mish_32', 'conv_32', 'bn_32', 'mish_33', 'shortcut_33', 'conv_34', 'bn_34', 'mish_35', 'conv_35', 'bn_35', 'mish_36', 'shortcut_36', 'conv_37', 'bn_37', 'mish_38', 'conv_38', 'bn_38', 'mish_39', 'shortcut_39', 'conv_40', 'bn_40', 'mish_41', 'conv_41', 'bn_41', 'mish_42', 'shortcut_42', 'conv_43', 'bn_43', 'mish_44', 'conv_44', 'bn_44', 'mish_45', 'shortcut_45', 'conv_46', 'bn_46', 'mish_47', 'conv_47', 'bn_47', 'mish_48', 'shortcut_48', 'conv_49', 'bn_49', 'mish_50', 'conv_50', 'bn_50', 'mish_51', 'shortcut_51', 'conv_52', 'bn_52', 'mish_53', 'concat_53', 'conv_54', 'bn_54', 'mish_55', 'conv_55', 'bn_55', 'mish_56', 'conv_56', 'bn_56', 'mish_57', 'identity_57', 'conv_58', 'bn_58', 'mish_59', 'conv_59', 'bn_59', 'mish_60', 'conv_60', 'bn_60', 'mish_61', 'shortcut_61', 'conv_62', 'bn_62', 'mish_63', 'conv_63', 'bn_63', 'mish_64', 'shortcut_64', 'conv_65', 'bn_65', 'mish_66', 'conv_66', 'bn_66', 'mish_67', 'shortcut_67', 'conv_68', 'bn_68', 'mish_69', 'conv_69', 'bn_69', 'mish_70', 'shortcut_70', 'conv_71', 'bn_71', 'mish_72', 'conv_72', 'bn_72', 'mish_73', 'shortcut_73', 'conv_74', 'bn_74', 'mish_75', 'conv_75', 'bn_75', 'mish_76', 'shortcut_76', 'conv_77', 'bn_77', 'mish_78', 'conv_78', 'bn_78', 'mish_79', 'shortcut_79', 'conv_80', 'bn_80', 'mish_81', 'conv_81', 'bn_81', 'mish_82', 'shortcut_82', 'conv_83', 'bn_83', 'mish_84', 'concat_84', 'conv_85', 'bn_85', 'mish_86', 'conv_86', 'bn_86', 'mish_87', 'conv_87', 'bn_87', 'mish_88', 'identity_88', 'conv_89', 'bn_89', 'mish_90', 'conv_90', 'bn_90', 'mish_91', 'conv_91', 'bn_91', 'mish_92', 'shortcut_92', 'conv_93', 'bn_93', 'mish_94', 'conv_94', 'bn_94', 'mish_95', 'shortcut_95', 'conv_96', 'bn_96', 'mish_97', 'conv_97', 'bn_97', 'mish_98', 'shortcut_98', 'conv_99', 'bn_99', 'mish_100', 'conv_100', 'bn_100', 'mish_101', 'shortcut_101', 'conv_102', 'bn_102', 'mish_103', 'concat_103', 'conv_104', 'bn_104', 'mish_105', 'conv_105', 'bn_105', 'leaky_106', 'conv_106', 'bn_106', 'leaky_107', 'conv_107', 'bn_107', 'leaky_108', 'pool_108', 'identity_109', 'pool_110', 'identity_111', 'pool_112', 'concat_113', 'conv_114', 'bn_114', 'leaky_115', 'conv_115', 'bn_115', 'leaky_116', 'conv_116', 'bn_116', 'leaky_117', 'conv_117', 'bn_117', 'leaky_118', 'upsample_118', 'identity_119', 'conv_120', 'bn_120', 'leaky_121', 'concat_121', 'conv_122', 'bn_122', 'leaky_123', 'conv_123', 'bn_123', 'leaky_124', 'conv_124', 'bn_124', 'leaky_125', 'conv_125', 'bn_125', 'leaky_126', 'conv_126', 'bn_126', 'leaky_127', 'conv_127', 'bn_127', 'leaky_128', 'upsample_128', 'identity_129', 'conv_130', 'bn_130', 'leaky_131', 'concat_131', 'conv_132', 'bn_132', 'leaky_133', 'conv_133', 'bn_133', 'leaky_134', 'conv_134', 'bn_134', 'leaky_135', 'conv_135', 'bn_135', 'leaky_136', 'conv_136', 'bn_136', 'leaky_137', 'conv_137', 'bn_137', 'leaky_138', 'conv_138', 'permute_139', 'yolo_139', 'identity_140', 'conv_141', 'bn_141', 'leaky_142', 'concat_142', 'conv_143', 'bn_143', 'leaky_144', 'conv_144', 'bn_144', 'leaky_145', 'conv_145', 'bn_145', 'leaky_146', 'conv_146', 'bn_146', 'leaky_147', 'conv_147', 'bn_147', 'leaky_148', 'conv_148', 'bn_148', 'leaky_149', 'conv_149', 'permute_150', 'yolo_150', 'identity_151', 'conv_152', 'bn_152', 'leaky_153', 'concat_153', 'conv_154', 'bn_154', 'leaky_155', 'conv_155', 'bn_155', 'leaky_156', 'conv_156', 'bn_156', 'leaky_157', 'conv_157', 'bn_157', 'leaky_158', 'conv_158', 'bn_158', 'leaky_159', 'conv_159', 'bn_159', 'leaky_160', 'conv_160', 'permute_161', 'yolo_161')\n","Total: 379\n","Camadas de saída: \n","[327 353 379]\n","['yolo_139', 'yolo_150', 'yolo_161']\n"]}]},{"cell_type":"markdown","metadata":{"id":"Iqc359lDATAh"},"source":["## Etapa 5 - Criando as funções para detecção e processamento do video\n"]},{"cell_type":"markdown","metadata":{"id":"r2w30TyWCcZu"},"source":["### Função para exibir imagens no Colab"]},{"cell_type":"code","metadata":{"id":"dg5ZQD6soINW","executionInfo":{"status":"ok","timestamp":1702993691067,"user_tz":180,"elapsed":6,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["def mostrar(img):\n","  fig = plt.gcf()\n","  fig.set_size_inches(16, 10)\n","  plt.axis(\"off\")\n","  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","  plt.show()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vat9IbYuzBE_"},"source":["### Construindo o blob da imagem\n"]},{"cell_type":"code","metadata":{"id":"OQ7J84o70ao8","executionInfo":{"status":"ok","timestamp":1702996378042,"user_tz":180,"elapsed":793,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["def detectionFunction(net, imagem, mostrar_texto=True):\n","  inicio = time.time()\n","  blob = cv2.dnn.blobFromImage(imagem, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n","  net.setInput(blob)\n","  layerOutputs = net.forward(ln)\n","  termino = time.time()\n","  if mostrar_texto:\n","    print(\"YOLO levou {:.2f} segundos\".format(termino - inicio))\n","  return net, imagem, layerOutputs"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Wkis49_-VxD"},"source":["### Realizando a detecção"]},{"cell_type":"code","metadata":{"id":"_MOUOfivV-c5","executionInfo":{"status":"ok","timestamp":1702996401107,"user_tz":180,"elapsed":261,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["def resultProcessing(detection, _threshold, caixas, confiancas, IDclasses):\n","  scores = detection[5:]\n","  classeID = np.argmax(scores)\n","  confianca = scores[classeID]\n","\n","  if confianca > _threshold:\n","      caixa = detection[0:4] * np.array([W, H, W, H])\n","      (centerX, centerY, width, height) = caixa.astype(\"int\")\n","\n","      x = int(centerX - (width / 2))\n","      y = int(centerY - (height / 2))\n","\n","      caixas.append([x, y, int(width), int(height)])\n","      confiancas.append(float(confianca))\n","      IDclasses.append(classeID)\n","\n","  return caixas, confiancas, IDclasses"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aOwTXTg--tYj"},"source":["### Mostrando o resultado da detecção no video"]},{"cell_type":"code","metadata":{"id":"-ETrpQKQ4pBa","executionInfo":{"status":"ok","timestamp":1702993908845,"user_tz":180,"elapsed":322,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["def funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=True):\n","  (x, y) = (caixas[i][0], caixas[i][1])#Get the top-left position of the bouding box\n","  (w, h) = (caixas[i][2], caixas[i][3])#Get the width and height of the bouding box\n","  cor = [int(c) for c in COLORS[IDclasses[i]]]#Get a random color in the random color array\n","  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2)#Defines a bounding box in the image\n","  fundo = np.full((imagem.shape), (0,0,0), dtype=np.uint8)#Create the background of the text\n","  texto = \"{}: {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])#Define the text of the bouding box\n","\n","  cv2.putText(fundo, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\n","\n","  fx,fy,fw,fh = cv2.boundingRect(fundo[:,:,2])\n","\n","  cv2.rectangle(imagem, (x, y), (x + w, y + h), cor, 2)\n","\n","  cv2.rectangle(imagem, (fx, fy), (fx + fw, fy + fh), cor, -1)\n","  cv2.rectangle(imagem, (fx, fy), (fx + fw, fy + fh), cor, 3)\n","  cv2.putText(imagem, texto, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1)\n","\n","  if mostrar_texto:\n","    print(\"> \" + texto)\n","    print(x,y,w,h)\n","\n","  return imagem,x,y,w,h"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bzv-6h7477z5"},"source":["## Etapa 6 - Carregando o vídeo onde será feita a detecção"]},{"cell_type":"markdown","metadata":{"id":"JmDcELnJOBTq"},"source":["### 6.1 - De uma url"]},{"cell_type":"code","metadata":{"id":"Jlrbm3mMOGhS","executionInfo":{"status":"ok","timestamp":1702993922710,"user_tz":180,"elapsed":764,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"5e29ad37-a483-4b1e-a11a-a3d0fba2e7e4","colab":{"base_uri":"https://localhost:8080/"}},"source":["!wget https://github.com/gabevr/yolo/raw/master/videos/video_pessoas01.mp4"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-19 13:52:03--  https://github.com/gabevr/yolo/raw/master/videos/video_pessoas01.mp4\n","Resolving github.com (github.com)... 140.82.113.4\n","Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/gabevr/yolo/master/videos/video_pessoas01.mp4 [following]\n","--2023-12-19 13:52:03--  https://raw.githubusercontent.com/gabevr/yolo/master/videos/video_pessoas01.mp4\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6129513 (5.8M) [application/octet-stream]\n","Saving to: ‘video_pessoas01.mp4’\n","\n","video_pessoas01.mp4 100%[===================>]   5.84M  --.-KB/s    in 0.03s   \n","\n","2023-12-19 13:52:03 (187 MB/s) - ‘video_pessoas01.mp4’ saved [6129513/6129513]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"NXCgPeVVOby6"},"source":["### Lendo o arquivo de vídeo com o OpenCV"]},{"cell_type":"code","metadata":{"id":"sp6UaJE5R7T0","executionInfo":{"status":"ok","timestamp":1702994041104,"user_tz":180,"elapsed":299,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["arquivo_video = 'video_pessoas01.mp4'#File name\n","cap = cv2.VideoCapture(arquivo_video)#Read the video\n","conectado, video = cap.read()"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVcmO4OmSS-h","executionInfo":{"status":"ok","timestamp":1702994041917,"user_tz":180,"elapsed":6,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"24864503-1a17-420d-eb60-e2f7e5eea172","colab":{"base_uri":"https://localhost:8080/"}},"source":["conectado"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"Lg6WM0noSaPt","executionInfo":{"status":"ok","timestamp":1702994042863,"user_tz":180,"elapsed":8,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"fbf662db-40e5-4ce9-ba60-efba0763a2dd","colab":{"base_uri":"https://localhost:8080/"}},"source":["video.shape"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(720, 1280, 3)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"4Cn2tQqfSgaZ","executionInfo":{"status":"ok","timestamp":1702994043562,"user_tz":180,"elapsed":3,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"7f61ff9e-0dc8-4834-f1fb-9a646bfc5b3a","colab":{"base_uri":"https://localhost:8080/"}},"source":["video_largura = video.shape[1]#width\n","video_altura = video.shape[0]#height\n","video_largura, video_altura"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1280, 720)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"JKqI-fx99utO"},"source":["## Etapa 7 - Redimensionamento do tamanho do video (opcional)"]},{"cell_type":"code","metadata":{"id":"S6Welhd3A5aM","executionInfo":{"status":"ok","timestamp":1702994045087,"user_tz":180,"elapsed":2,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["def redimensionar(largura, altura, largura_maxima = 600):\n","  if (largura > largura_maxima):\n","    proporcao = largura / altura\n","    video_largura = largura_maxima\n","    video_altura = int(video_largura / proporcao)\n","  else:\n","    video_largura = largura\n","    video_altura = altura\n","\n","  return video_largura, video_altura"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"unUjT4cZMrAa","executionInfo":{"status":"ok","timestamp":1702994046136,"user_tz":180,"elapsed":2,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"5efb2fe1-9369-43d1-8043-c73ef350b08b","colab":{"base_uri":"https://localhost:8080/"}},"source":["video_largura, video_altura = redimensionar(video.shape[1], video.shape[0])\n","print(video_largura,video_altura)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["600 337\n"]}]},{"cell_type":"markdown","metadata":{"id":"zmTdl-SXByYW"},"source":["## Etapa 8 - Definindo as configurações do vídeo\n","\n","- Mais exemplos de outras configurações com o fourcc que é possível usar: https://www.programcreek.com/python/example/89348/cv2.VideoWriter_fourcc"]},{"cell_type":"code","metadata":{"id":"kX__kKpYTE5Q","executionInfo":{"status":"ok","timestamp":1702994223546,"user_tz":180,"elapsed":290,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["nome_arquivo = 'resultado.avi'#Say the name of the result file\n","fourcc = cv2.VideoWriter_fourcc(*'XVID') # Say that the result file will be saved as a .avi"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"0moxehGETvyr","executionInfo":{"status":"ok","timestamp":1702994223887,"user_tz":180,"elapsed":5,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["fps = 24#Define the final FPS"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmXS8Y7VT0rI","executionInfo":{"status":"ok","timestamp":1702994224785,"user_tz":180,"elapsed":2,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["saida_video = cv2.VideoWriter(nome_arquivo, fourcc, fps, (video_largura, video_altura))"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BQzpImT4-H1F"},"source":["## Etapa 9 - Definindo as variáveis"]},{"cell_type":"code","metadata":{"id":"8AUrERe_UQgs","executionInfo":{"status":"ok","timestamp":1702994226348,"user_tz":180,"elapsed":5,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["threshold = 0.5\n","threshold_NMS = 0.3\n","fonte_pequena, fonte_media = 0.4, 0.6\n","fonte = cv2.FONT_HERSHEY_SIMPLEX"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"FMJ8RhqsUliW","executionInfo":{"status":"ok","timestamp":1702996762761,"user_tz":180,"elapsed":262,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["amostras_exibir = 10#Number of frames that will be shown\n","amostra_atual = 0"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ifu1dDTKP-mX"},"source":["## Etapa 10 - Processamento do vídeo e exibição do resultado"]},{"cell_type":"code","metadata":{"id":"Yak18CwkU1_Y","executionInfo":{"status":"ok","timestamp":1702997658627,"user_tz":180,"elapsed":890875,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"54c886d6-a16f-408a-8bc4-03e86f7f89dd","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fLzllD95S87gPgBXRuWALLmRcwGj-lIl"}},"source":["while (cv2.waitKey(1) < 0):#While the user didnt clicked in the keyboard\n","  conectado, frame = cap.read()#Get the frame\n","  if not conectado:# If the video end\n","    break#Break the loop\n","  t = time.time()#Start the timer\n","  frame = cv2.resize(frame, (video_largura, video_altura))# Resize the image\n","  try:\n","    (H, W) = frame.shape[:2]#Det the height and the width\n","  except:\n","    print('Erro')\n","    continue\n","\n","  imagem_cp = frame.copy()#Creates a copy of the frame\n","  net, frame, layerOutputs = detectionFunction(net, frame)#Try detect the objects\n","  caixas = []\n","  confiancas = []\n","  IDclasses = []\n","\n","  for output in layerOutputs:#For each output layer\n","    for detection in output:#For each object detected in the output layer\n","      caixas, confiancas, IDclasses = resultProcessing(detection, threshold, caixas, confiancas, IDclasses)#Process the result\n","\n","  objs = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)#Apply the Non-max suppression\n","\n","  if len(objs) > 0:#If exist some object detected\n","    for i in objs.flatten():#For each object detected\n","      frame, x, y, w, h = funcoes_imagem(frame, i, confiancas, caixas, COLORS, LABELS, mostrar_texto=False)#\n","\n","  cv2.putText(frame, \" frame processado em {:.2f} segundos\".format(time.time() - t),\n","              (20, video_altura-20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)# Put the processing time of the frame\n","\n","  if amostra_atual <= amostras_exibir:#Show the first 10 frames\n","    cv2_imshow(frame)\n","    amostra_atual += 1\n","\n","  saida_video.write(frame)#Add this processed frame in the video object\n","\n","print('Terminou')\n","saida_video.release()#close the process\n","cv2.destroyAllWindows()#Close the window"],"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"2fdV8vq6aEO5","executionInfo":{"status":"ok","timestamp":1702997841056,"user_tz":180,"elapsed":279,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}},"outputId":"5490d59f-0083-4344-af38-0c6fe1a728a1","colab":{"base_uri":"https://localhost:8080/"}},"source":["!du -h resultado.avi"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["14M\tresultado.avi\n"]}]},{"cell_type":"code","metadata":{"id":"HKuk7P8aaF4B","executionInfo":{"status":"ok","timestamp":1702997884201,"user_tz":180,"elapsed":410,"user":{"displayName":"Kauã Moreira","userId":"03647449924368994635"}}},"source":["!cp ./resultado.avi /content/gdrive/MyDrive/Yolo/resultados/resultado3.avi"],"execution_count":44,"outputs":[]}]}